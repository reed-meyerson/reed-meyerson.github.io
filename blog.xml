<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Reed Meyerson</title>
<link>https://reedmeyerson.com/blog.html</link>
<atom:link href="https://reedmeyerson.com/blog.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Wed, 21 Jan 2026 05:00:00 GMT</lastBuildDate>
<item>
  <title>Speculative Decoding is not a Heuristic</title>
  <dc:creator>Reed Meyerson</dc:creator>
  <link>https://reedmeyerson.com/posts/speculative_decoding_not_heuristic/</link>
  <description><![CDATA[ 





<section id="the-basic-idea" class="level1 page-columns page-full">
<h1>The Basic Idea</h1>
<p>Speculative decoding<sup><span class="citation" data-cites="leviathan2023fast">[1]</span>,<span class="citation" data-cites="chen2023accelerating">[2]</span></sup> is an inference technique for increasing the throughput of an LLM. In its most basic form, there is a large/slow <strong>target model</strong> and a small/fast <strong>draft model</strong>. The draft model is used to quickly generate a <strong>draft sequence</strong> of the next <img src="https://latex.codecogs.com/png.latex?N"> tokens<sup>1</sup>. Then, a single pass of the target model is used to obtain <img src="https://latex.codecogs.com/png.latex?N+1"> next-token distributions<sup>2</sup>. A <strong>verification procedure</strong> takes the above information into consideration and decides how much of the draft sequence to accept (i.e.&nbsp;determine some <img src="https://latex.codecogs.com/png.latex?M%5Cle%20N">, and keep the first <img src="https://latex.codecogs.com/png.latex?M"> draft tokens). Finally, an <img src="https://latex.codecogs.com/png.latex?(M+1)%5E%7B%5Ctext%7Bst%7D%7D"> token, which we will call the <strong>continuation token</strong><sup>3</sup>, is sampled either directly from the target model’s next-token distribution for that position or from some modified distribution.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;as well as the <img src="https://latex.codecogs.com/png.latex?N"> next-token distributions from the draft model that each draft token was sampled from</p></div><div id="fn2"><p><sup>2</sup>&nbsp;one for each position in the draft sequence, and one that will be used to sample an additional token at the very end if the entire draft sequence is accepted</p></div><div id="fn3"><p><sup>3</sup>&nbsp;this is not a standard term, but it will be useful for this token to have a name</p></div><div id="fn4"><p><sup>4</sup>&nbsp;the accepted tokens and the continuation token</p></div></div><p>When the verification step accepts at least one token from the draft sequence, we will be generating multiple tokens from a single forward pass of the target model<sup>4</sup>. Thus, when the cost of running the draft model is low and the average number of tokens accepted per round is high, we can expect a meaningful increase in the overall throughput of the target model.</p>
</section>
<section id="is-this-a-heuristic" class="level1">
<h1>Is this a Heuristic?</h1>
<p>When I first read about speculative decoding, I thought, “What an interesting heuristic”. It was obvious that it could improve the inference-time throughput of a model, but it was <em>not</em> obvious that it could do so without effecting output quality.</p>
<p>Clearly, speculative decoding <em>can</em> be a heuristic. For instance, one idea could be to look at the probability of a draft token in the target distribution and accept it if this target probability exceeds some threshold. Take a minute, and I’m sure you can come up with a few variants of ‘accept the tokens that are <em>good enough</em>’ and reject the rest. Many of these heuristics will effect the output quality of the model.</p>
<p>Since we have established that speculative decoding <em>can</em> be a heuristic, perhaps a better question is: “Is speculative decoding <em>necessarily</em> a heuristic?”</p>
<p>To answer this, we should define what it means to <em>not</em> be a heuristic. In simple terms, we would like the result of speculative decoding to have the same behavior as the target model. For determinstic functions ‘same behavior’ is easy to define: the same input for both functions will always produce idential outputs. However, LLMs are probabilistic models. The target model can generate multiple different outputs from the same input. For a given context, there is some probability of the target model generating one output sequence, and there is another probability of it generating some other output sequence.</p>
<p>Thus, what we mean by ‘same behavior’ is that speculative decoding should generate the same <em>distribution</em> of outputs. That is, given a particular context, the probability of continuing it with a particular sequence of tokens should be the same for the speculative decoding algorithm and the target model. If this is the case for all valid contexts and continuation sequences, we say that the speculative decoding algorithm is <strong>lossless</strong>.</p>
</section>
<section id="naive-rejection-sampling" class="level1 page-columns page-full">
<h1>Naive Rejection Sampling</h1>
<p>Consider the following verification procedure: “always reject the entire draft sequence, and sample the continuation token from the target distribution”. This trivial example clearly offers no improvement to inference speed. However, it is also clearly lossless, so it merits some extra attention<sup>5</sup>.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;some say that’s all you need</p></div></div><p>Consider the case where the first draft token happens to match the continuation token. In this case, we might as well accept the draft token and sample a new continuation token in the second position. Again, if this new continuation token happens to match the second draft token, we might as well accept the first and second draft tokens and sample the continuation token in the third position. We can continue this process until either the draft token does not match the continuation token, or we have accepted all draft tokens. Take some time to convince yourself that this policy is lossless. We will call this modification of the trivial example <strong>naive rejection sampling</strong>.</p>
<p>For naive rejection sampling, the acceptance rate at any given position is the probability that the draft and target distributions will yield the same token when sampled independently. In general, the acceptance rate will be positive<sup>6</sup>, but potentially small<sup>7</sup>.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;unless the draft and target distributions have disjoint support, but this would not be typical</p></div><div id="fn7"><p><sup>7</sup>&nbsp;unless both models are highly confident about the same single output token</p></div><div id="fn8"><p><sup>8</sup>&nbsp;i.e.&nbsp;each of the 100 tokens has a probability of 1/100 of being selected</p></div></div><p>Even in the scenario that the draft and target next-token distributions are <em>identical</em>, the acceptance rate of naive rejection sampling can be quite small. Consider the case where the vocabulary has 100 tokens, and both distributions are the uniform distribution<sup>8</sup>. The acceptance rate of naive rejection sampling will be 1/100. However, in this situation we <em>could have</em> accepted the draft token with a probability of 1. This is because the draft and target distributions are identical, so the draft token is <em>already</em> sampled from the target distribution.</p>
<p>Of course, we would not expect the draft and target distributions to be identical. However, this does provide hope that we can substantially beat naive rejection sampling when the draft and target distributions are <em>similar</em>.</p>
</section>
<section id="token-by-token-verification-procedures" class="level1 page-columns page-full">
<h1>Token-by-Token Verification Procedures</h1>
<p>In principle, verification can be any procedure that stochastically accepts some portion of the draft sequence and samples a continuation token after considering the <em>entire</em> sequence of draft tokens, draft next-token distributions, target next-token distributions, and context. For example, “<em>If the draft sequence contains the word ‘apple’, then accept the entire sequence. Otherwise, reject the entire sequence. In either case, sample the continuation token from the uniform distribution.</em>” is a valid verification procedure<sup>9</sup>.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;though, obviously not lossless</p></div></div><p>To simplify things, we restrict our attention to verification procedures which consider only one token at a time, and accept/resample based only on the following information:</p>
<ol type="1">
<li>The draft next-token distribution <em>in that position</em></li>
<li>The target next-token distribution <em>in that position</em></li>
<li>The draft token <em>in that position</em></li>
</ol>
<p>Furthermore, when the verification procedure does not accept the entire draft sequence, we assume that the continuation token is distinct from the draft token in that position<sup>10</sup>.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;otherwise, we should have accepted that draft token</p></div></div><p>Any verification procedure with these properties is called a <strong>token-by-token</strong> verification procedure.</p>
<p>It is worth noting that there are verification procedures which <em>do</em> wholistically consider the entire sequence of draft/target distributions and draft tokens<sup><span class="citation" data-cites="sun2025block">[3]</span></sup>. Indeed, these <em>block-level</em> verification procedures outperform token-by-token verification. However, they build on the ideas from the token-by-token literature and are better suited for a future blog post.</p>
<p>To analyze a single step of a token-by-token verification procedure, we need some notation. Let <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BV%7D=%5C%7Ba_i%5C%7D_%7Bi=1%7D%5EV"> be the shared vocabulary<sup>11</sup> for the draft and target models. For a fixed step of a chosen verification procedure, and any pair of tokens <img src="https://latex.codecogs.com/png.latex?a_i,a_j%5Cin%5Cmathcal%7BV%7D">, there is some probability of <img src="https://latex.codecogs.com/png.latex?a_i"> being the draft token and <img src="https://latex.codecogs.com/png.latex?a_j"> being the resulting token. Thus, we define</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;i.e.&nbsp;the set of possible output tokens</p></div></div><p><img src="https://latex.codecogs.com/png.latex?%0A%5CPi_%7Bij%7D=%5Ctext%7Bthe%20probability%20that%20%7Da_i%5Ctext%7B%20is%20the%20draft%20token%20and%20%7Da_j%5Ctext%7B%20is%20the%20output%20token%7D.%0A"></p>
<p>Then, acceptance occurs when <img src="https://latex.codecogs.com/png.latex?a_i=a_j">, and the probability of acceptance is obtained by summing along the diagonal:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5EV%5CPi_%7Bii%7D%0A"></p>
<p>Let <img src="https://latex.codecogs.com/png.latex?p"> be the next-token distribution for the draft model and <img src="https://latex.codecogs.com/png.latex?q"> be the next-token distribution for the target model<sup>12</sup>. Let <img src="https://latex.codecogs.com/png.latex?X"> be the random variable for the draft token (i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?X%5Csim%20p">). Let <img src="https://latex.codecogs.com/png.latex?Y"> be the random variable that is result of the verification procedure. Then, the pair of random variables <img src="https://latex.codecogs.com/png.latex?(X,Y)"> is dependent and their joint distribution is described by <img src="https://latex.codecogs.com/png.latex?%5CPi">. Finally, let <img src="https://latex.codecogs.com/png.latex?Z"> be the random variable that is obtained by sampling independently from the target distribution <img src="https://latex.codecogs.com/png.latex?q">.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;for the single, fixed position in question</p></div></div><p>We define <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0Ap_i%20&amp;=%20P(X=a_i)%5C%5C%0Aq_i%20&amp;=%20P(Z=a_i)%5C%5C%0A%5Cend%7Balign*%7D%0A"></p>
<p>With the notation above, we can expand <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5CPi_%7Bij%7D&amp;=P(X=a_i%5Cland%20Y=a_j)%5C%5C%0A%20%20%20%20&amp;=P(Y=a_j%7CX=a_i)P(X=a_i)%5C%5C%0A%20%20%20%20&amp;=P(Y=a_j%7CX=a_i)p_i%0A%5Cend%7Balign*%7D%0A"></p>
<p>It follows that <img src="https://latex.codecogs.com/png.latex?%5CPi"> satisfies the following constraints<sup>13</sup></p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;the sum is just formally stating that the draft token needs to follow the draft distribution</p></div></div><p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%5Csum_%7Bj=1%7D%5EV%5CPi_%7Bij%7D&amp;=p_i%5C%5C%0A%5CPi_%7Bij%7D&amp;%5Cge%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>In fact, the converse is also true. Any <img src="https://latex.codecogs.com/png.latex?V%5Ctimes%20V"> matrix <img src="https://latex.codecogs.com/png.latex?%5CPi"> satisfying the above constraints can be used to carry out a single step of the token-by-token verification procedure<sup>14</sup>.</p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;once you have <img src="https://latex.codecogs.com/png.latex?X=a_i">, select <img src="https://latex.codecogs.com/png.latex?Y"> with probabilities <img src="https://latex.codecogs.com/png.latex?P(Y=a_j%7CX=a_i)=%5Cfrac%7B%5CPi_%7Bij%7D%7D%7Bp_i%7D"></p></div></div><p>The output distribution is obtained by summing along the first index</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0AP(Y=a_j)&amp;=%5Csum_%7Bi=1%7D%5EVP(Y=a_j%7CX=a_i)P(X=a_i)%5C%5C%0A%20%20&amp;=%5Csum_%7Bi=1%7D%5EV%5CPi_%7Bij%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Thus, the step is lossless if and only if <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5EV%5CPi_%7Bij%7D=q_j%0A"></p>
<p>An optimal lossless verification step in a token-by-token verification procedure corresponds to finding a matrix <img src="https://latex.codecogs.com/png.latex?%5CPi"> satisfying the above constraints which maximizes the acceptance rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%5Ctextbf%7Bmaximize%7D%5C%5C%0A%5Csum_%7Bi=1%7D%5EV%20%5CPi_%7Bii%7D%5C%5C%0A%5Ctextbf%7Bsubject%20to%7D%5C%5C%0A%5Csum_%7Bj=1%7D%5EV%5CPi_%7Bij%7D%20&amp;=%20p_i%5C%5C%0A%5Csum_%7Bi=1%7D%5EV%20%5CPi_%7Bij%7D%20&amp;=%20q_j%5C%5C%0A%5CPi_%7Bij%7D%20&amp;%5Cge%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Maximizing the acceptance rate is equivalent to minimizing the rejection rate<sup>15</sup>: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%5Ctextbf%7Bminimize%7D%5C%5C%0A%5Csum_%7Bi%5Cneq%20j%7D%20%5CPi_%7Bij%7D%5C%5C%0A%5Ctextbf%7Bsubject%20to%7D%5C%5C%0A%5Csum_%7Bj=1%7D%5EV%5CPi_%7Bij%7D%20&amp;=%20p_i%5C%5C%0A%5Csum_%7Bi=1%7D%5EV%20%5CPi_%7Bij%7D%20&amp;=%20q_j%5C%5C%0A%5CPi_%7Bij%7D%20&amp;%5Cge%200%0A%5Cend%7Balign*%7D%0A"></p>
<div class="no-row-height column-margin column-container"><div id="fn15"><p><sup>15</sup>&nbsp;the rejection rate is just the sum of the off-diagonal terms of <img src="https://latex.codecogs.com/png.latex?%5CPi"></p></div></div><p>Thus, we have a <a href="https://en.wikipedia.org/wiki/Linear_programming">linear program</a>:</p>
<ul>
<li>A utility function, token acceptance rate (or cost function, token rejection rate), which is linear in the coefficients of <img src="https://latex.codecogs.com/png.latex?%5CPi"></li>
<li>A set of equality and inequality constraints that are linear in the coefficients of <img src="https://latex.codecogs.com/png.latex?%5CPi"></li>
<li>An objective to maximize the utility function (or minimize the cost function)</li>
</ul>
<p>There are a variety of methods for finding exact and approximate solutions to linear programs. However, this one is relatively simple and admits a closed-form solution<sup>16</sup>:</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;showing that this is, in fact, a solution to the linear program is a good exercise to check that you understand the constraints and objective</p></div></div><p><img src="https://latex.codecogs.com/png.latex?%0A%5CPi%5E%7B%5Ctext%7Boptimal%7D%7D_%7Bij%7D%20=%20%5Cbegin%7Bcases%7D%0A%20%20%5Cmin%5C%7Bp_i,q_i%5C%7D&amp;%5Ctext%7Bif%20%7Di%20=%20j%5C%5C%0A%20%20%5Cfrac%7B(p_i-%5Cmin%5C%7Bp_i,q_i%5C%7D)(q_j-%5Cmin%5C%7Bp_j,q_j%5C%7D)%7D%7B1-%5Cbeta(p,q)%7D&amp;%5Ctext%7Belse%7D%0A%5Cend%7Bcases%7D%0A"></p>
<p>where</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta(p,q)=%5Csum_%7Bi=1%7D%5EV%5Cmin%5C%7Bp_i,q_i%5C%7D%0A"></p>
<p>For this solution, <img src="https://latex.codecogs.com/png.latex?%5Cbeta(p,q)"> is the acceptance rate, and it is easy to see that <img src="https://latex.codecogs.com/png.latex?%5Cbeta(p,q)"> approaches 1 as <img src="https://latex.codecogs.com/png.latex?p"> approaches <img src="https://latex.codecogs.com/png.latex?q">.</p>
</section>
<section id="optimal-transport" class="level1 page-columns page-full">
<h1>Optimal Transport</h1>
<p>The matrix <img src="https://latex.codecogs.com/png.latex?%5CPi"> defines a probability distribution on the product space <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BV%7D%5Ctimes%5Cmathcal%7BV%7D"> <sup>17</sup>. This distribution has two marginal distributions. One marginal, obtained by summing on the second index, is always the draft distribution, <img src="https://latex.codecogs.com/png.latex?p">. In the lossless case, the other marginal is the target distribution, <img src="https://latex.codecogs.com/png.latex?q">. Such a distribution is called a <strong>transport plan</strong> from <img src="https://latex.codecogs.com/png.latex?p"> to <img src="https://latex.codecogs.com/png.latex?q">. Intuitively, starting with a distribution <img src="https://latex.codecogs.com/png.latex?p">, a transport plan describes how to redistribute the mass from <img src="https://latex.codecogs.com/png.latex?p"> to obtain <img src="https://latex.codecogs.com/png.latex?q">.</p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;recall, it is the probability of getting a pair <img src="https://latex.codecogs.com/png.latex?(a_i,a_j)"> of draft/output tokens</p></div></div><p>Given a cost function, <img src="https://latex.codecogs.com/png.latex?C(i,j)"> which describes the cost of moving mass from <img src="https://latex.codecogs.com/png.latex?i"> to <img src="https://latex.codecogs.com/png.latex?j">, the total cost of a transport plan from <img src="https://latex.codecogs.com/png.latex?p"> to <img src="https://latex.codecogs.com/png.latex?q"> is defined by</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi,j%7DC(i,j)%5CPi(i,j)%0A"></p>
<p>We say that a transport plan from <img src="https://latex.codecogs.com/png.latex?p"> to <img src="https://latex.codecogs.com/png.latex?q"> is <strong>optimal</strong><sup>18</sup>, if has minimal total transport cost amongst all transport plans from <img src="https://latex.codecogs.com/png.latex?p"> to <img src="https://latex.codecogs.com/png.latex?q">.</p>
<div class="no-row-height column-margin column-container"><div id="fn18"><p><sup>18</sup>&nbsp;with respect to <img src="https://latex.codecogs.com/png.latex?C"></p></div></div><p>Returning to token-by-token verification, we can let <img src="https://latex.codecogs.com/png.latex?C(i,j)=%5Cbegin%7Bcases%7D0&amp;%5Ctext%7Bif%20%7Di=j%5C%5C1&amp;%5Ctext%7Bif%20%7D%20i%20%5Cneq%20j%5Cend%7Bcases%7D">. This assigns a cost of zero when accepting a token and a cost of 1 when rejecting a token. With this cost function, the total cost of a transport plan is just the overall probability of rejection.</p>
<p>It is straightforward to see that the linear program described at the end of the previous section is equivalent to the following optimal transport problem: find a transport plan from <img src="https://latex.codecogs.com/png.latex?p"> to <img src="https://latex.codecogs.com/png.latex?q"> which is optimal with respect to the cost, <img src="https://latex.codecogs.com/png.latex?C">, defined above.</p>
<p>As stated earlier, this optimal transport problem is relatively simple and admits a closed-form solution. Thus, in the simple setting of single-draft, token-by-token speculative decoding, rephrasing the problem in terms of optimal transport mostly adds a new conceptual perspective. However, in more complex situations, such as multi-draft speculative decoding<sup><span class="citation" data-cites="sun2024spectr">[4]</span></sup>, optimal transport provies a powerful toolbox for solving the problem. Perhaps we can cover that in a future post.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body">
<div id="ref-leviathan2023fast" class="csl-entry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Leviathan, Y., Kalman, M., and Matias, Y. (2023). <a href="https://arxiv.org/abs/2211.17192">Fast inference from transformers via speculative decoding</a>.</div>
</div>
<div id="ref-chen2023accelerating" class="csl-entry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Chen, C., Borgeaud, S., Irving, G., Lespiau, J.-B., Sifre, L., and Jumper, J. (2023). <a href="https://arxiv.org/abs/2302.01318">Accelerating large language model decoding with speculative sampling</a>.</div>
</div>
<div id="ref-sun2025block" class="csl-entry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Sun, Z., Mendlovic, U., Leviathan, Y., Aharoni, A., Ro, J.H., Beirami, A., and Suresh, A.T. (2025). <a href="https://arxiv.org/abs/2403.10444">Block verification accelerates speculative decoding</a>.</div>
</div>
<div id="ref-sun2024spectr" class="csl-entry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Sun, Z., Suresh, A.T., Ro, J.H., Beirami, A., Jain, H., and Yu, F. (2024). <a href="https://arxiv.org/abs/2310.15141">SpecTr: Fast speculative decoding via optimal transport</a>.</div>
</div>
</div></section></div> ]]></description>
  <category>LLMs</category>
  <category>speculative decoding</category>
  <category>optimal transport</category>
  <category>linear programming</category>
  <guid>https://reedmeyerson.com/posts/speculative_decoding_not_heuristic/</guid>
  <pubDate>Wed, 21 Jan 2026 05:00:00 GMT</pubDate>
</item>
<item>
  <title>The Ancients had Ops</title>
  <dc:creator>Reed Meyerson</dc:creator>
  <link>https://reedmeyerson.com/posts/ancient_ops/</link>
  <description><![CDATA[ 





<section id="a-bit-of-history" class="level1 page-columns page-full">
<h1>A Bit of History</h1>
<p>Pyramid building, tax collection, and war waging are not exactly simple enterprises. So complex are these operations, that their management requires a great technology. A technology so transformational, our modern Ops stacks pale in comparison. I speak, of course, of the technology of <em>writing</em>.</p>
<p>Writing first appeared over 5,000 years ago in the ancient Mesopotamian civilization of Sumer. The invention of writing was so closely coincident with that of bookkeeping, auditing, and other administrative practices that it is reasonable to say it was <em>invented for the purpose of bookkeeping</em><sup><span class="citation" data-cites="smolinski1992search">[1]</span>,<span class="citation" data-cites="goody1986logic">[2]</span></sup>. In fact, roughly 90 percent of surviving ancient Sumerian tablets served administrative purposes<sup><span class="citation" data-cites="woods2010visible">[3]</span></sup>. Sumerian scribes kept detailed records of a vast array of transactions – no matter how big or small. Examples range from “a barge full of grain to a dead fowl”<sup><span class="citation" data-cites="keister1963commercial">[4]</span></sup>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="cuneiform.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Example of a Sumerian tablet summarizing account of silver@pict."><img src="https://reedmeyerson.com/posts/ancient_ops/cuneiform.png" class="img-fluid figure-img" style="width:50.0%" alt="Example of a Sumerian tablet summarizing account of silver[5]."></a></p>
<figcaption>Example of a Sumerian tablet summarizing account of silver<sup><span class="citation" data-cites="pict">[5]</span></sup>.</figcaption>
</figure>
</div>
<p>Why would a society go through so much trouble? What is the administrative value of good record-keeping? Fundamentally, record-keeping in the 4th millennium BC and in modernity provides the same value: to be able to reason about the past so that better decisions can be made in the future. All good Ops<sup>2</sup> must keep this as a primary objective.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;MLOps, DevOps, PyramidOps, TaxOps, WarOps, CyclOps, LollipOps, FlipflOps, TriceratOps, BarbershOps, MuttonchOps, MountaintOps, ArchbishOps, etc…</p></div></div></section>
<section id="why-automate" class="level1 page-columns page-full">
<h1>Why Automate?</h1>
<p>For many, MLOps<sup>3</sup> is synonymous with automation. This is like equating carpentry with the use of power tools. Yes, power tools offer incredible utility to the craft of carpentry, but carpentry is so much more than the use of a table saw. Similarly, automation is an incredible tool for MLOps, but it is not an end unto itself.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;and the earlier coined “DevOps”</p></div></div><p>In further error, the utility of automation is too often limited to “doing things faster”. All else being equal, speeding up a process is worthwhile, but it is hardly the only objective worth optimizing for. Well-crafted automations lead to improvements in</p>
<ul>
<li>reliability</li>
<li>repeatability</li>
<li>auditability</li>
<li>and yes… “doing things faster”</li>
</ul>
<p>The following famous <a href="https://xkcd.com/1205/">xkcd</a> comic is still a good rule of thumb, but only if you interpret “How Much Time You Shave Off” more broadly.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="is_it_worth_the_time_2x.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="credit: https://xkcd.com/1205"><img src="https://reedmeyerson.com/posts/ancient_ops/is_it_worth_the_time_2x.png" class="img-fluid figure-img" alt="credit: https://xkcd.com/1205"></a></p>
<figcaption>credit: https://xkcd.com/1205</figcaption>
</figure>
</div>
<p>Here are some examples of hidden time savings:</p>
<ul>
<li>After a benchmark, the resulting report is automatically stored in a standard location
<ul>
<li>Congratulations! You no longer need to ping your colleague on Slack to ask where they put that report.</li>
</ul></li>
<li>Before training a model, the information about input datasets is automatically stored
<ul>
<li>Congratulations! In three weeks, when you realize your model is doing ‘suspiciously well’ on a specific subset of the benchmark set, you can check for data leakage without needing to retrain your model.</li>
</ul></li>
<li>Before training a model, the computational environment used for training is automatically stored
<ul>
<li>Congratulations! When you need to retrain this model in six weeks, you don’t need to spend time remembering exactly which magic combination of shell commands and software versions are required to get things running again.</li>
</ul></li>
</ul>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body">
<div id="ref-smolinski1992search" class="csl-entry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Smolinski, H.C., Chumley, D.W., and Bennett, D.E. (1992). In search of ancient auditors. Accounting Historians Notebook <em>15</em>, 6.</div>
</div>
<div id="ref-goody1986logic" class="csl-entry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Goody, J. (1986). The logic of writing and the organization of society (Cambridge University Press).</div>
</div>
<div id="ref-woods2010visible" class="csl-entry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Woods, C., and Woods, C.E. (2010). Visible language: Inventions of writing in the ancient middle east and beyond;[in conjunction with the exhibition visible language: Inventions of writing in the ancient middle east and beyond] (Oriental Institute of the University of Chicago).</div>
</div>
<div id="ref-keister1963commercial" class="csl-entry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Keister, O.R. (1963). Commercial record keeping in ancient mesopotamia. The Accounting Review <em>38</em>, 371.</div>
</div>
<div id="ref-pict" class="csl-entry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Gavin.collins (2013). Sumerian account of silver for the govenor (background removed). <a href="https://commons.wikimedia.org/wiki/File:Sumerian_account_of_silver_for_the_govenor_%28background_removed%29.png">https://commons.wikimedia.org/wiki/File:Sumerian_account_of_silver_for_the_govenor_%28background_removed%29.png</a>.</div>
</div>
</div></section></div> ]]></description>
  <category>MLOps</category>
  <category>reproducibility</category>
  <category>auditability</category>
  <category>automation</category>
  <category>history</category>
  <guid>https://reedmeyerson.com/posts/ancient_ops/</guid>
  <pubDate>Thu, 14 Nov 2024 05:00:00 GMT</pubDate>
  <media:content url="https://reedmeyerson.com/posts/ancient_ops/cuneiform.png" medium="image" type="image/png" height="143" width="144"/>
</item>
<item>
  <title>Generative AI doesn’t need to be flashy</title>
  <dc:creator>Reed Meyerson</dc:creator>
  <link>https://reedmeyerson.com/posts/boring_generative_AI/</link>
  <description><![CDATA[ 





<p>Generative AI is the new hotness. It’s flashy, exciting, full of pizazz. There’s a certain showmanship in asking a machine for an image of a monkey riding a unicycle and having it spit out an image of a monkey riding a unicycle.</p>
<p>Most data scientists don’t deal with such exciting things. For most companies, pictures of monkeys riding unicycles have no effect on the bottom line; these flashy displays have seemingly nothing to do with business analytics. However, the techniques of generative AI are not inherently flashy and have many potential applications.</p>
<div class="page-columns page-full"><p>This is the first in a series of posts on <strong>Generative Diffusion Models</strong><sup>*,<span class="citation" data-cites="sohldickstein2015deep">[1]</span>,<span class="citation" data-cites="ho2020denoising">[2]</span>,<span class="citation" data-cites="song2021scorebased">[3]</span></sup> . In this post, I argue that the intersection of “generative models like reverse diffusion” and “tools used to solve non-flashy problems” should be non-zero. In future posts we will implement reverse diffusion models, use them to solve inverse problems, explore their latent spaces, and utilize them as building blocks for unsupervised techniques.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">*: AKA the models used to generate images from sentences.</span></div></div>
<div class="page-columns page-full"><p>Generative diffusion models are techniques for learning<sup>†</sup> a probability distribution from data. When applying these models, we hope that the learned distribution is similar to the ground-truth distribution that the original data was sampled from.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">†: or learning to sample/resample from</span></div></div>
<p>In this post, we will not discuss <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">how generative diffusion models work</a> (that will come later). Instead, we will accept what they <strong>accomplish</strong>:</p>
<ol type="1">
<li>Generative diffusion models can approximate any probability distribution<sup>‡</sup>(or conditional probability distribution).</li>
<li>Empirically, they seem to generalize well<sup>§</sup>.</li>
</ol>
<div class="no-row-height column-margin column-container"><span class="margin-aside">‡: given sufficiently many parameters, of course</span><span class="margin-aside">§: That is, they seem to do well at finding points outside of the original data that are consistent with the original data</span></div><section id="why-should-i-learn-a-probability-distribution" class="level1 page-columns page-full">
<h1>Why should I “learn” a probability distribution?</h1>
<p>The following examples demonstrate why it is sometimes necessary to learn a distribution of values rather than estimate a single value or fit a fixed function.</p>
<section id="forecasting" class="level2">
<h2 class="anchored" data-anchor-id="forecasting">Forecasting</h2>
<p>Your boss comes to you with the following time series:</p>
<div id="960448a5" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3264</span>)</span>
<span id="cb1-4">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb1-5">plt.stem(x)</span>
<span id="cb1-6">plt.xticks([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>],[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'present'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'future'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>])</span>
<span id="cb1-7">plt.show()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://reedmeyerson.com/posts/boring_generative_AI/index_files/figure-html/cell-2-output-1.png" width="582" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There are 50 data points from the past and they want you to predict the next 50 in the future. After analyzing the data, you determine this is standard Gaussian noise. Thus, the likelihood for the next 50 points is proportional to a Gaussian,</p>
<p><img src="https://latex.codecogs.com/png.latex?p(x_%7B51%7D,x_%7B52%7D,%5Ccdots,x_%7B100%7D)%20%5Cpropto%20e%5E%7B-(x_%7B51%7D%5E2+x_%7B52%7D%5E2+%5Ccdots%20+x_%7B100%7D%5E2)/2%7D"></p>
<p>and is maximized when all values are zero. You conclude that the most likely prediction for the future is given by</p>
<p><img src="https://latex.codecogs.com/png.latex?x_%7B51%7D=x_%7B52%7D=%5Ccdots=x_%7B100%7D=0"></p>
<p>You plot your prediction and show it to your boss:</p>
<div id="2d0e3642" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">x_future <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb2-2">plt.stem(np.concatenate((x,x_future)))</span>
<span id="cb2-3">plt.xticks([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>],[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'present'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'future'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>])</span>
<span id="cb2-4">plt.show()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://reedmeyerson.com/posts/boring_generative_AI/index_files/figure-html/cell-3-output-1.png" width="582" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>To which your boss complains that the left half of the plot looks nothing like the right half, so this can’t possibly be right.</p>
<p>The issue here is that the <em>most likely</em> future is not a <em>typical</em> future. However, there is not a single typical future or a <em>most typical</em> future; there are a <em>distribution</em> of typical futures, and knowing that distribution is the goal of forecasting.</p>
<p>If <img src="https://latex.codecogs.com/png.latex?p"> is a distribution of time series that you believe your time series is from, the problem of forecasting can be stated as learning the distribution of the future values conditioned on the past measurements. That is, to simulate the future, we want to sample</p>
<p><img src="https://latex.codecogs.com/png.latex?x%20%5Csim%20p(%5Ctexttt%7Bfuture%7D%7C%5Ctexttt%7Bpast%7D)"></p>
<p>Of course, in this case, the exact solution is relatively simple, <img src="https://latex.codecogs.com/png.latex?x_%7B51%5Cto%20100%7D%20%5Csim%20%5Cmathcal%7BN%7D(0,I_%7B50%5Ctimes%2050%7D)"> and simple statistics, Bayesian inference, or standard forecasting techniques like ARIMA should all yield something similar to the ground truth distribution.</p>
</section>
<section id="image-deblurringwhang2021deblurring-and-inpaintinglugmayr2022repaint" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="image-deblurringwhang2021deblurring-and-inpaintinglugmayr2022repaint">Image deblurring<sup><span class="citation" data-cites="whang2021deblurring">[4]</span></sup>, and inpainting<sup><span class="citation" data-cites="lugmayr2022repaint">[5]</span></sup></h2>
<p>When a blurry image is taken, some information about the original scene is lost. That is, given a blurry image, we can’t say with certainty which specific clear image it came from. There might be a ‘most likely’ clear image, but as before, that most likely image might not be very typical, and it doesn’t tell us much about the distribution of clear images the blurry image might have come from. Thus, it is unnatural to solve this as a regression problem, by training a single deterministic function</p>
<p><img src="https://latex.codecogs.com/png.latex?f%20:%5Ctexttt%7Bblurry%20images%7D%5Cto%20%5Ctexttt%7Bclear%20images%7D"></p>
<div class="page-columns page-full"><p>Rather, let <img src="https://latex.codecogs.com/png.latex?p"> be the distribution of <img src="https://latex.codecogs.com/png.latex?(%5Ctexttt%7Bclear%20image%7D,%5Ctexttt%7Bblurry%20image%7D)"> pairs. We can recast the image deblurring problem as sampling from the marginal distribution of clear images conditioned on the blurry image marginal value<sup>*</sup>.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">*: it is useful to think of conditional sampling <img src="https://latex.codecogs.com/png.latex?X%5Csim%20p(x%7Cy)"> as a stochastic function with input <img src="https://latex.codecogs.com/png.latex?y"> and output <img src="https://latex.codecogs.com/png.latex?X"></span></div></div>
<p><img src="https://latex.codecogs.com/png.latex?x%20%5Csim%20p(%5Ctexttt%7Bclear%20image%7D%7C%5Ctexttt%7Bblurry%20image%7D)"></p>
<p>Similarly, for inpainting, there may be many ways to fill an unknown region with plausible pixel values. If <img src="https://latex.codecogs.com/png.latex?q"> is a distribution of images, then we can cast inpainting as conditionally sampling the unkown region given the known region.</p>
<p><img src="https://latex.codecogs.com/png.latex?x%20%5Csim%20q(%5Ctexttt%7Bunknown%20region%7D%20%7C%20%5Ctexttt%7Bknown%20region%7D)"></p>
<p>For these examples, generative diffusion is a great candidate for modeling these distributions because</p>
<ol type="1">
<li>Distributions of images are very complicated<sup>†</sup></li>
<li>We care about getting the intricacies of the distribution correct, because the human visual system is very sensitive</li>
<li>There are large data sets of images</li>
</ol>
<div class="no-row-height column-margin column-container"><span class="margin-aside">†: so we want a universal distribution approximator</span></div><p>In particular, item (2.) is something we cannot overlook. Before using a technique as expensive as generative diffusion, ask yourself if you really need the accuracy. Even if your distribution is very complicated, it may be perfectly acceptable to underfit.</p>
</section>
<section id="inverse-problems" class="level2">
<h2 class="anchored" data-anchor-id="inverse-problems">Inverse Problems</h2>
<p>Broadly speaking, an inverse problem is to reconstruct a system from information about that system. Often, we think of the act of obtaining the information as a “measurement”. For some inverse problems, the measurements uniquely specify the system. In this case, we can try to form a deterministic function that reconstructs the system from the information</p>
<p><img src="https://latex.codecogs.com/png.latex?f:%5Ctexttt%7Binformation%7D%20%5Cto%20%5Ctexttt%7Bsystem%7D"></p>
<p>Deblurring and inpainting are both inverse problems. The system is the original image, and the information we have is the blurred image or the obstructed image, respectively. However, as we noted before, given a specific measurement (i.e.&nbsp;a specific blurred/obstructed image) there is not a single system (i.e.&nbsp;a clear/unobstructed image) that the measurement could have come from. When this is the case, we say the inverse problem is ill-posed. Ill-posed inverse problems can be solved by determining the conditional distribution</p>
<p><img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7Bsystem%7D%7C%5Ctexttt%7Bmeasurements%7D)"></p>
<p>Intuitively, this conditional distribution tells you</p>
<ol type="1">
<li>What different systems could have produced the measurements you obtained</li>
<li>How likely each of these possible systems are</li>
</ol>
<p>“Find out about something from measurements/information” is hilariously broad. Thus, inverse problems are everywhere. Here is a very small list:</p>
<ul>
<li>Medical Imaging
<ul>
<li>X-ray tomography: <img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7Binside%20your%20body%7D%20%7C%20%5Ctexttt%7Bhow%20radiation%20propogates%20through%20you%7D)"></li>
<li>Ultrasound: <img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7Binside%20your%20body%7D%20%7C%20%5Ctexttt%7Bhow%20vibrations%20propogate%20through%20you%7D)"></li>
<li>Electrical Impedence Tomography: <img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7Binside%20your%20body%7D%20%7C%20%5Ctexttt%7Bhow%20voltages%20propogate%20through%20you%7D)"></li>
</ul></li>
<li>Finance/Economics
<ul>
<li><img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7Bmacroeconomic%20quantitites%7D%7C%5Ctexttt%7Bmicroeconomic%20observables%7D)"></li>
<li><img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7BBlack-Scholes%20equation%20coefficients%7D%7C%5Ctexttt%7Basset%20time%20series%7D)"></li>
<li><img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7Ba%20firm's%20private%20market%20beliefs%7D%7C%5Ctexttt%7Bpublic%20trading%20data%7D)"></li>
</ul></li>
<li>Geophysics
<ul>
<li><img src="https://latex.codecogs.com/png.latex?p(%5Ctexttt%7Binside%20the%20earth%7D%7C%5Ctexttt%7Bearthquake%20wave%20propogation%20times%7D)"></li>
</ul></li>
</ul>
<p>The list is practically endless. Your company is almost certainly either solving one or more inverse problems or consuming the solutions of one or more inverse problems.</p>
</section>
</section>
<section id="should-i-use-generative-diffusion" class="level1 page-columns page-full">
<h1>Should I use generative diffusion?</h1>
<p>We have established that “learning probability distributions” is a very important tool for solving inverse problems, and inverse problems are everywhere. So, you should probably care about learning probability distributions.</p>
<p>But it still remains: why generative diffusion? There are simpler, more computationally efficient and more interpretable models from classical and Bayesian statistics. Not to mention other generative machine learning models like a GANs or auto encoders.</p>
<div class="page-columns page-full"><p>This question is similar to the question “Should I use a neural network in a regression problem?”<sup>*</sup>. Generative diffusion models, as tools for learning distributions are high variance and low bias. The low bias is consistent with the fact that they are expressive enough to approximate any probability distribution. However, you will need a lot of data to counteract the high variance.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">*: in short, most of the time: ‘No.’</span></div></div>
<p>Here are some things to consider:</p>
<ul>
<li>Can I model my system explicitly?</li>
<li>Is my distribution very complicated?</li>
<li>How much do I care about underfitting? (Can I <em>pretend</em> that it is not complicated and still get good results?)</li>
<li>Do I have a lot of data, and if not, can I employ transfer learning?</li>
<li>Do I have the computational budget for training and inference?</li>
<li>Do I need to be able to interpret the distribution?</li>
<li>What do I need to <em>do</em> with the distribution? Sample from it, or something else?</li>
</ul>
<p>Most people will get to the end of this list and realize there are better tools to solve their problem. However, some people will realize that they have a very complicated distribution, and they care deeply about capturing its intricacies. It will be worth it for them to collect the large amount of data required and allocate a large computational budget.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body">
<div id="ref-sohldickstein2015deep" class="csl-entry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Sohl-Dickstein, J., Weiss, E.A., Maheswaranathan, N., and Ganguli, S. (2015). <a href="https://arxiv.org/abs/1503.03585">Deep unsupervised learning using nonequilibrium thermodynamics</a>.</div>
</div>
<div id="ref-ho2020denoising" class="csl-entry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Ho, J., Jain, A., and Abbeel, P. (2020). <a href="https://arxiv.org/abs/2006.11239">Denoising diffusion probabilistic models</a>.</div>
</div>
<div id="ref-song2021scorebased" class="csl-entry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Song, Y., Sohl-Dickstein, J., Kingma, D.P., Kumar, A., Ermon, S., and Poole, B. (2021). <a href="https://arxiv.org/abs/2011.13456">Score-based generative modeling through stochastic differential equations</a>.</div>
</div>
<div id="ref-whang2021deblurring" class="csl-entry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Whang, J., Delbracio, M., Talebi, H., Saharia, C., Dimakis, A.G., and Milanfar, P. (2021). <a href="https://arxiv.org/abs/2112.02475">Deblurring via stochastic refinement</a>.</div>
</div>
<div id="ref-lugmayr2022repaint" class="csl-entry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Lugmayr, A., Danelljan, M., Romero, A., Yu, F., Timofte, R., and Gool, L.V. (2022). <a href="https://arxiv.org/abs/2201.09865">RePaint: Inpainting using denoising diffusion probabilistic models</a>.</div>
</div>
</div></section></div> ]]></description>
  <category>generative models</category>
  <category>probability</category>
  <category>inverse problems</category>
  <category>generative diffusion</category>
  <category>unsupervised learning</category>
  <category>machine learning</category>
  <guid>https://reedmeyerson.com/posts/boring_generative_AI/</guid>
  <pubDate>Sun, 19 Mar 2023 04:00:00 GMT</pubDate>
  <media:content url="https://reedmeyerson.com/posts/boring_generative_AI/time_series_mle.png" medium="image" type="image/png" height="102" width="144"/>
</item>
</channel>
</rss>
