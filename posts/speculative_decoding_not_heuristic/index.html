<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Reed Meyerson">
<meta name="dcterms.date" content="2026-01-21">
<meta name="description" content="Speculative decoding is a technique which uses a fast draft model to accelerate the inference of a slow target model. With the right verification procedure, speculative decoding can be lossless (i.e.&nbsp;it reproduces the quality of the target model). For token-by-token verification procedures, the criteria for lossless decoding can be written as a system of linear equations and inequalities. The acceptance rate, which directly controls model throughput, is also linear in the same variables. Thus, the optimal verification procedure is obtained by solving a linear program. This linear program is equivalent to an optimal transport problem from the draft distribution to the target distribution.">

<title>Speculative Decoding is not a Heuristic – Reed Meyerson</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ffa9a6279353761231ec249df0a7fdd3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Speculative Decoding is not a Heuristic – Reed Meyerson">
<meta property="og:description" content="Speculative decoding is a technique which uses a fast draft model to accelerate the inference of a slow target model. With the right verification procedure, speculative decoding can be lossless (i.e.&nbsp;it reproduces the quality of the target model). For token-by-token verification procedures, the criteria for lossless decoding can be written as a system of linear equations and inequalities. The acceptance rate, which directly controls model throughput, is also linear in the same variables. Thus, the optimal verification procedure is obtained by solving a linear program. This linear program is equivalent to an optimal transport problem from the draft distribution to the target distribution.">
<meta property="og:site_name" content="Reed Meyerson">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Reed Meyerson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publications.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Speculative Decoding is not a Heuristic</h1>
            <p class="subtitle lead">Increase LLM Speed Without Sacrificing Quality</p>
                  <div>
        <div class="description">
          Speculative decoding is a technique which uses a fast <em>draft model</em> to accelerate the inference of a slow <em>target model</em>. With the right verification procedure, speculative decoding can be lossless (i.e.&nbsp;it reproduces the quality of the target model). For token-by-token verification procedures, the criteria for lossless decoding can be written as a system of linear equations and inequalities. The acceptance rate, which directly controls model throughput, is also linear in the same variables. Thus, the optimal verification procedure is obtained by solving a linear program. This linear program is equivalent to an optimal transport problem from the draft distribution to the target distribution.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">speculative decoding</div>
                <div class="quarto-category">optimal transport</div>
                <div class="quarto-category">linear programming</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Reed Meyerson </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 21, 2026</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-basic-idea" id="toc-the-basic-idea" class="nav-link active" data-scroll-target="#the-basic-idea">The Basic Idea</a></li>
  <li><a href="#is-this-a-heuristic" id="toc-is-this-a-heuristic" class="nav-link" data-scroll-target="#is-this-a-heuristic">Is this a Heuristic?</a></li>
  <li><a href="#naive-rejection-sampling" id="toc-naive-rejection-sampling" class="nav-link" data-scroll-target="#naive-rejection-sampling">Naive Rejection Sampling</a></li>
  <li><a href="#token-by-token-verification-procedures" id="toc-token-by-token-verification-procedures" class="nav-link" data-scroll-target="#token-by-token-verification-procedures">Token-by-Token Verification Procedures</a></li>
  <li><a href="#optimal-transport" id="toc-optimal-transport" class="nav-link" data-scroll-target="#optimal-transport">Optimal Transport</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="the-basic-idea" class="level1 page-columns page-full">
<h1>The Basic Idea</h1>
<p>Speculative decoding<sup><span class="citation" data-cites="leviathan2023fast">[<a href="#ref-leviathan2023fast" role="doc-biblioref">1</a>]</span>,<span class="citation" data-cites="chen2023accelerating">[<a href="#ref-chen2023accelerating" role="doc-biblioref">2</a>]</span></sup> is an inference technique for increasing the throughput of an LLM. In its most basic form, there is a large/slow <strong>target model</strong> and a small/fast <strong>draft model</strong>. The draft model is used to quickly generate a <strong>draft sequence</strong> of the next <span class="math inline">\(N\)</span> tokens<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Then, a single pass of the target model is used to obtain <span class="math inline">\(N+1\)</span> next-token distributions<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. A <strong>verification procedure</strong> takes the above information into consideration and decides how much of the draft sequence to accept (i.e.&nbsp;determine some <span class="math inline">\(M\le N\)</span>, and keep the first <span class="math inline">\(M\)</span> draft tokens). Finally, an <span class="math inline">\((M+1)^{\text{st}}\)</span> token, which we will call the <strong>continuation token</strong><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, is sampled either directly from the target model’s next-token distribution for that position or from some modified distribution.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;as well as the <span class="math inline">\(N\)</span> next-token distributions from the draft model that each draft token was sampled from</p></div><div id="fn2"><p><sup>2</sup>&nbsp;one for each position in the draft sequence, and one that will be used to sample an additional token at the very end if the entire draft sequence is accepted</p></div><div id="fn3"><p><sup>3</sup>&nbsp;this is not a standard term, but it will be useful for this token to have a name</p></div><div id="fn4"><p><sup>4</sup>&nbsp;the accepted tokens and the continuation token</p></div></div><p>When the verification step accepts at least one token from the draft sequence, we will be generating multiple tokens from a single forward pass of the target model<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Thus, when the cost of running the draft model is low and the average number of tokens accepted per round is high, we can expect a meaningful increase in the overall throughput of the target model.</p>
</section>
<section id="is-this-a-heuristic" class="level1">
<h1>Is this a Heuristic?</h1>
<p>When I first read about speculative decoding, I thought, “What an interesting heuristic”. It was obvious that it could improve the inference-time throughput of a model, but it was <em>not</em> obvious that it could do so without effecting output quality.</p>
<p>Clearly, speculative decoding <em>can</em> be a heuristic. For instance, one idea could be to look at the probability of a draft token in the target distribution and accept it if this target probability exceeds some threshold. Take a minute, and I’m sure you can come up with a few variants of ‘accept the tokens that are <em>good enough</em>’ and reject the rest. Many of these heuristics will effect the output quality of the model.</p>
<p>Since we have established that speculative decoding <em>can</em> be a heuristic, perhaps a better question is: “Is speculative decoding <em>necessarily</em> a heuristic?”</p>
<p>To answer this, we should define what it means to <em>not</em> be a heuristic. In simple terms, we would like the result of speculative decoding to have the same behavior as the target model. For determinstic functions ‘same behavior’ is easy to define: the same input for both functions will always produce idential outputs. However, LLMs are probabilistic models. The target model can generate multiple different outputs from the same input. For a given context, there is some probability of the target model generating one output sequence, and there is another probability of it generating some other output sequence.</p>
<p>Thus, what we mean by ‘same behavior’ is that speculative decoding should generate the same <em>distribution</em> of outputs. That is, given a particular context, the probability of continuing it with a particular sequence of tokens should be the same for the speculative decoding algorithm and the target model. If this is the case for all valid contexts and continuation sequences, we say that the speculative decoding algorithm is <strong>lossless</strong>.</p>
</section>
<section id="naive-rejection-sampling" class="level1 page-columns page-full">
<h1>Naive Rejection Sampling</h1>
<p>Consider the following verification procedure: “always reject the entire draft sequence, and sample the continuation token from the target distribution”. This trivial example clearly offers no improvement to inference speed. However, it is also clearly lossless, so it merits some extra attention<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;some say that’s all you need</p></div></div><p>Consider the case where the first draft token happens to match the continuation token. In this case, we might as well accept the draft token and sample a new continuation token in the second position. Again, if this new continuation token happens to match the second draft token, we might as well accept the first and second draft tokens and sample the continuation token in the third position. We can continue this process until either the draft token does not match the continuation token, or we have accepted all draft tokens. Take some time to convince yourself that this policy is lossless. We will call this modification of the trivial example <strong>naive rejection sampling</strong>.</p>
<p>For naive rejection sampling, the acceptance rate at any given position is the probability that the draft and target distributions will yield the same token when sampled independently. In general, the acceptance rate will be positive<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, but potentially small<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;unless the draft and target distributions have disjoint support, but this would not be typical</p></div><div id="fn7"><p><sup>7</sup>&nbsp;unless both models are highly confident about the same single output token</p></div><div id="fn8"><p><sup>8</sup>&nbsp;i.e.&nbsp;each of the 100 tokens has a probability of 1/100 of being selected</p></div></div><p>Even in the scenario that the draft and target next-token distributions are <em>identical</em>, the acceptance rate of naive rejection sampling can be quite small. Consider the case where the vocabulary has 100 tokens, and both distributions are the uniform distribution<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. The acceptance rate of naive rejection sampling will be 1/100. However, in this situation we <em>could have</em> accepted the draft token with a probability of 1. This is because the draft and target distributions are identical, so the draft token is <em>already</em> sampled from the target distribution.</p>
<p>Of course, we would not expect the draft and target distributions to be identical. However, this does provide hope that we can substantially beat naive rejection sampling when the draft and target distributions are <em>similar</em>.</p>
</section>
<section id="token-by-token-verification-procedures" class="level1 page-columns page-full">
<h1>Token-by-Token Verification Procedures</h1>
<p>In principle, verification can be any procedure that stochastically accepts some portion of the draft sequence and samples a continuation token after considering the <em>entire</em> sequence of draft tokens, draft next-token distributions, target next-token distributions, and context. For example, “<em>If the draft sequence contains the word ‘apple’, then accept the entire sequence. Otherwise, reject the entire sequence. In either case, sample the continuation token from the uniform distribution.</em>” is a valid verification procedure<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;though, obviously not lossless</p></div></div><p>To simplify things, we restrict our attention to verification procedures which consider only one token at a time, and accept/resample based only on the following information:</p>
<ol type="1">
<li>The draft next-token distribution <em>in that position</em></li>
<li>The target next-token distribution <em>in that position</em></li>
<li>The draft token <em>in that position</em></li>
</ol>
<p>Furthermore, when the verification procedure does not accept the entire draft sequence, we assume that the continuation token is distinct from the draft token in that position<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;otherwise, we should have accepted that draft token</p></div></div><p>Any verification procedure with these properties is called a <strong>token-by-token</strong> verification procedure.</p>
<p>It is worth noting that there are verification procedures which <em>do</em> wholistically consider the entire sequence of draft/target distributions and draft tokens<sup><span class="citation" data-cites="sun2025block">[<a href="#ref-sun2025block" role="doc-biblioref">3</a>]</span></sup>. Indeed, these <em>block-level</em> verification procedures outperform token-by-token verification. However, they build on the ideas from the token-by-token literature and are better suited for a future blog post.</p>
<p>To analyze a single step of a token-by-token verification procedure, we need some notation. Let <span class="math inline">\(\mathcal{V}=\{a_i\}_{i=1}^V\)</span> be the shared vocabulary<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> for the draft and target models. For a fixed step of a chosen verification procedure, and any pair of tokens <span class="math inline">\(a_i,a_j\in\mathcal{V}\)</span>, there is some probability of <span class="math inline">\(a_i\)</span> being the draft token and <span class="math inline">\(a_j\)</span> being the resulting token. Thus, we define</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;i.e.&nbsp;the set of possible output tokens</p></div></div><p><span class="math display">\[
\Pi_{ij}=\text{the probability that }a_i\text{ is the draft token and }a_j\text{ is the output token}.
\]</span></p>
<p>Then, acceptance occurs when <span class="math inline">\(a_i=a_j\)</span>, and the probability of acceptance is obtained by summing along the diagonal:</p>
<p><span class="math display">\[
\sum_{i=1}^V\Pi_{ii}
\]</span></p>
<p>Let <span class="math inline">\(p\)</span> be the next-token distribution for the draft model and <span class="math inline">\(q\)</span> be the next-token distribution for the target model<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. Let <span class="math inline">\(X\)</span> be the random variable for the draft token (i.e.&nbsp;<span class="math inline">\(X\sim p\)</span>). Let <span class="math inline">\(Y\)</span> be the random variable that is result of the verification procedure. Then, the pair of random variables <span class="math inline">\((X,Y)\)</span> is dependent and their joint distribution is described by <span class="math inline">\(\Pi\)</span>. Finally, let <span class="math inline">\(Z\)</span> be the random variable that is obtained by sampling independently from the target distribution <span class="math inline">\(q\)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;for the single, fixed position in question</p></div></div><p>We define <span class="math display">\[
\begin{align*}
p_i &amp;= P(X=a_i)\\
q_i &amp;= P(Z=a_i)\\
\end{align*}
\]</span></p>
<p>With the notation above, we can expand <span class="math display">\[
\begin{align*}
  \Pi_{ij}&amp;=P(X=a_i\land Y=a_j)\\
    &amp;=P(Y=a_j|X=a_i)P(X=a_i)\\
    &amp;=P(Y=a_j|X=a_i)p_i
\end{align*}
\]</span></p>
<p>It follows that <span class="math inline">\(\Pi\)</span> satisfies the following constraints<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;the sum is just formally stating that the draft token needs to follow the draft distribution</p></div></div><p><span class="math display">\[
\begin{align*}
\sum_{j=1}^V\Pi_{ij}&amp;=p_i\\
\Pi_{ij}&amp;\ge 0
\end{align*}
\]</span></p>
<p>In fact, the converse is also true. Any <span class="math inline">\(V\times V\)</span> matrix <span class="math inline">\(\Pi\)</span> satisfying the above constraints can be used to carry out a single step of the token-by-token verification procedure<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;once you have <span class="math inline">\(X=a_i\)</span>, select <span class="math inline">\(Y\)</span> with probabilities <span class="math inline">\(P(Y=a_j|X=a_i)=\frac{\Pi_{ij}}{p_i}\)</span></p></div></div><p>The output distribution is obtained by summing along the first index</p>
<p><span class="math display">\[
\begin{align*}
P(Y=a_j)&amp;=\sum_{i=1}^VP(Y=a_j|X=a_i)P(X=a_i)\\
  &amp;=\sum_{i=1}^V\Pi_{ij}
\end{align*}
\]</span></p>
<p>Thus, the step is lossless if and only if <span class="math display">\[
\sum_{i=1}^V\Pi_{ij}=q_j
\]</span></p>
<p>An optimal lossless verification step in a token-by-token verification procedure corresponds to finding a matrix <span class="math inline">\(\Pi\)</span> satisfying the above constraints which maximizes the acceptance rate:</p>
<p><span class="math display">\[
\begin{align*}
\textbf{maximize}\\
\sum_{i=1}^V \Pi_{ii}\\
\textbf{subject to}\\
\sum_{j=1}^V\Pi_{ij} &amp;= p_i\\
\sum_{i=1}^V \Pi_{ij} &amp;= q_j\\
\Pi_{ij} &amp;\ge 0
\end{align*}
\]</span></p>
<p>Maximizing the acceptance rate is equivalent to minimizing the rejection rate<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>: <span class="math display">\[
\begin{align*}
\textbf{minimize}\\
\sum_{i\neq j} \Pi_{ij}\\
\textbf{subject to}\\
\sum_{j=1}^V\Pi_{ij} &amp;= p_i\\
\sum_{i=1}^V \Pi_{ij} &amp;= q_j\\
\Pi_{ij} &amp;\ge 0
\end{align*}
\]</span></p>
<div class="no-row-height column-margin column-container"><div id="fn15"><p><sup>15</sup>&nbsp;the rejection rate is just the sum of the off-diagonal terms of <span class="math inline">\(\Pi\)</span></p></div></div><p>Thus, we have a <a href="https://en.wikipedia.org/wiki/Linear_programming">linear program</a>:</p>
<ul>
<li>A utility function, token acceptance rate (or cost function, token rejection rate), which is linear in the coefficients of <span class="math inline">\(\Pi\)</span></li>
<li>A set of equality and inequality constraints that are linear in the coefficients of <span class="math inline">\(\Pi\)</span></li>
<li>An objective to maximize the utility function (or minimize the cost function)</li>
</ul>
<p>There are a variety of methods for finding exact and approximate solutions to linear programs. However, this one is relatively simple and admits a closed-form solution<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>:</p>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;showing that this is, in fact, a solution to the linear program is a good exercise to check that you understand the constraints and objective</p></div></div><p><span class="math display">\[
\Pi^{\text{optimal}}_{ij} = \begin{cases}
  \min\{p_i,q_i\}&amp;\text{if }i = j\\
  \frac{(p_i-\min\{p_i,q_i\})(q_j-\min\{p_j,q_j\})}{1-\beta(p,q)}&amp;\text{else}
\end{cases}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\beta(p,q)=\sum_{i=1}^V\min\{p_i,q_i\}
\]</span></p>
<p>For this solution, <span class="math inline">\(\beta(p,q)\)</span> is the acceptance rate, and it is easy to see that <span class="math inline">\(\beta(p,q)\)</span> approaches 1 as <span class="math inline">\(p\)</span> approaches <span class="math inline">\(q\)</span>.</p>
</section>
<section id="optimal-transport" class="level1 page-columns page-full">
<h1>Optimal Transport</h1>
<p>The matrix <span class="math inline">\(\Pi\)</span> defines a probability distribution on the product space <span class="math inline">\(\mathcal{V}\times\mathcal{V}\)</span> <a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>. This distribution has two marginal distributions. One marginal, obtained by summing on the second index, is always the draft distribution, <span class="math inline">\(p\)</span>. In the lossless case, the other marginal is the target distribution, <span class="math inline">\(q\)</span>. Such a distribution is called a <strong>transport plan</strong> from <span class="math inline">\(p\)</span> to <span class="math inline">\(q\)</span>. Intuitively, starting with a distribution <span class="math inline">\(p\)</span>, a transport plan describes how to redistribute the mass from <span class="math inline">\(p\)</span> to obtain <span class="math inline">\(q\)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;recall, it is the probability of getting a pair <span class="math inline">\((a_i,a_j)\)</span> of draft/output tokens</p></div></div><p>Given a cost function, <span class="math inline">\(C(i,j)\)</span> which describes the cost of moving mass from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>, the total cost of a transport plan from <span class="math inline">\(p\)</span> to <span class="math inline">\(q\)</span> is defined by</p>
<p><span class="math display">\[
\sum_{i,j}C(i,j)\Pi(i,j)
\]</span></p>
<p>We say that a transport plan from <span class="math inline">\(p\)</span> to <span class="math inline">\(q\)</span> is <strong>optimal</strong><a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>, if has minimal total transport cost amongst all transport plans from <span class="math inline">\(p\)</span> to <span class="math inline">\(q\)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn18"><p><sup>18</sup>&nbsp;with respect to <span class="math inline">\(C\)</span></p></div></div><p>Returning to token-by-token verification, we can let <span class="math inline">\(C(i,j)=\begin{cases}0&amp;\text{if }i=j\\1&amp;\text{if } i \neq j\end{cases}\)</span>. This assigns a cost of zero when accepting a token and a cost of 1 when rejecting a token. With this cost function, the total cost of a transport plan is just the overall probability of rejection.</p>
<p>It is straightforward to see that the linear program described at the end of the previous section is equivalent to the following optimal transport problem: find a transport plan from <span class="math inline">\(p\)</span> to <span class="math inline">\(q\)</span> which is optimal with respect to the cost, <span class="math inline">\(C\)</span>, defined above.</p>
<p>As stated earlier, this optimal transport problem is relatively simple and admits a closed-form solution. Thus, in the simple setting of single-draft, token-by-token speculative decoding, rephrasing the problem in terms of optimal transport mostly adds a new conceptual perspective. However, in more complex situations, such as multi-draft speculative decoding<sup><span class="citation" data-cites="sun2024spectr">[<a href="#ref-sun2024spectr" role="doc-biblioref">4</a>]</span></sup>, optimal transport provies a powerful toolbox for solving the problem. Perhaps we can cover that in a future post.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="list">
<div id="ref-leviathan2023fast" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Leviathan, Y., Kalman, M., and Matias, Y. (2023). <a href="https://arxiv.org/abs/2211.17192">Fast inference from transformers via speculative decoding</a>.</div>
</div>
<div id="ref-chen2023accelerating" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Chen, C., Borgeaud, S., Irving, G., Lespiau, J.-B., Sifre, L., and Jumper, J. (2023). <a href="https://arxiv.org/abs/2302.01318">Accelerating large language model decoding with speculative sampling</a>.</div>
</div>
<div id="ref-sun2025block" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Sun, Z., Mendlovic, U., Leviathan, Y., Aharoni, A., Ro, J.H., Beirami, A., and Suresh, A.T. (2025). <a href="https://arxiv.org/abs/2403.10444">Block verification accelerates speculative decoding</a>.</div>
</div>
<div id="ref-sun2024spectr" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Sun, Z., Suresh, A.T., Ro, J.H., Beirami, A., Jain, H., and Yu, F. (2024). <a href="https://arxiv.org/abs/2310.15141">SpecTr: Fast speculative decoding via optimal transport</a>.</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/reedmeyerson\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>